TASK 5:
The bug is in line 93: 

if (lane == 31) { ptr[warpid] = const_cast<T&>(ptr[idx]); } 

because for CUDA block 1024:
    - thread id `1023` has `warpid = 31` and it writes in `ptr[31]`
    - thread id `31`   has `idx = 31` and reads `ptr[31]`
Hence we have a datarace. Please notice that thread id `1023` must be involved because of the `lane == 31` condition which only allows execution of the last elememnt in a warp.

It can be fixed by splitting the instruction into a read and a write and inserting a barrier between them. Even better, they can observe that the value needed to be stored is already computed in `val`. 
 
TASK 6:
a) The code for processing each strip of 64 components is given below:

LOOP:   L.V   V1, 0(R2), R6     /load X; R6 contains the stride of 1.
        L.V   V2, 0(R3), R6     /load Y; 0(R3) is the base address of Y
        MUL.V V3, V2, V1        /Multiply two vector registers
        ADD.V V4, V4, V3        /Partial sums accumulate in V4
        ADDI  R2, R2, #64       /This assumes doubles
        ADDI  R3, R3, #64  
        BNE   R4, R5, LOOP

Partial vector sums accumulate in V4. At the end we simply have to add the components of V4. If vector components have 8 bytes (double precision) and memory is byte-addressable, then the increments on the address registers should be 512.

b) Given that vector operations are chained, one iteration of the loop takes:

Tite = latency(L.V) + latency(MUL.V)+ latency(ADD.V) +(V.L) - 1 = 30+10+5+64-1 = 108 cycles.   (or 109 is fine as well).

Since the loop has to iterate 16 times (16=1024/64), the total number of cycles taken by a dot-product is 108*16 =1728 cycles (ignoring the scalar phase at the end).

c) For the multiplication of two matrices, a component of the result matrix is obtained by a dot-product of two vectors. Therefore, we need 1024*1024= 1048576 dot-products to multiply two 1024*1024 matrices. The matrix multiply takes 1728*1048576 = 1.812*10 9 cycles.
